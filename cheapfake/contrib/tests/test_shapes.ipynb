{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests the shapes of the model outputs are what we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time \n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "\n",
    "import cheapfake.contrib.models as models\n",
    "import cheapfake.contrib.dataset as dataset\n",
    "import cheapfake.contrib.transforms as transforms\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction step took 44.5778021812439 seconds\n"
     ]
    }
   ],
   "source": [
    "random_seed = 41\n",
    "metadata_path = \"/home/shu/cheapfake/cheapfake/contrib/balanced_metadata_fs03.csv\"\n",
    "\n",
    "dfdataset = dataset.DeepFakeDataset(metadata_path=metadata_path, frame_transform=transforms.BatchRescale(4), sequential_audio=True, random_seed=random_seed, verbose=False)\n",
    "frames, audio, audio_stft = dfdataset.__getitem__(41)\n",
    "frames = frames[:75]\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.CheapFake(device=device)\n",
    "\n",
    "start_time = time.time()\n",
    "landmarks, fan_embedding, lipnet_embedding = model(frames.float().cuda(), audio.float().cuda())\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Prediction step took {} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])\n",
      "torch.Size([1, 256])\n"
     ]
    }
   ],
   "source": [
    "print(fan_embedding.shape)\n",
    "print(lipnet_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(torch.cat((fan_embedding, lipnet_embedding), axis=0).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to create embeddings for the LipNet output as well.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LipNetEncoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LipNetEncoder, self).__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnorm1 = torch.nn.BatchNorm2d(16)\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = torch.nn.Conv2d(16, 25, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm2d(25)\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.fc1 = torch.nn.Linear(25 * 18 * 128, 256)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lipnet_encoder = LipNetEncoder().cuda()\n",
    "reshaped_embedding = lipnet_embedding[None, :, :, None]\n",
    "reshaped_embedding = reshaped_embedding.permute(0, -1, 1, 2)\n",
    "print(reshaped_embedding.shape)\n",
    "output = lipnet_encoder(reshaped_embedding.float().cuda())\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cat((fan_embedding, output), axis=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"/home/shu/i2ai\")\n",
    "from mmid.audio_models.VGGVox import VGGVox\n",
    "from mmid.audio_models.ResNetSE34L import ResNetSE34L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_model = ResNetSE34L()\n",
    "audio_embeddings = audio_model(audio_stft.view(audio_stft.shape[0], -1).float())\n",
    "print(audio_embeddings.shape)\n",
    "\n",
    "print(torch.cat((fan_embedding, output, audio_embeddings.to(device)), axis=0).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the integration of the above code with code recently edited in models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.CheapFake(device=device)\n",
    "\n",
    "start_time = time.time()\n",
    "fan_output, fan_embedding, lipnet_embedding = model(frames.float().to(device))\n",
    "end_time = time.time()\n",
    "\n",
    "print(fan_output.shape)\n",
    "print(fan_embedding.shape)\n",
    "print(lipnet_embedding.shape)\n",
    "print(\"Entire operation took {} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
